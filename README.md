# TensorFlow-LiveLessons
This repository is home to the code that accompanies the *Deep Learning with TensorFlow* LiveLessons that will become available within the [O'Reilly Safari](https://www.safaribooksonline.com/) environment in August 2017. 

## Installation

Step-by-step guides for running the code in this repository can be found in the [installation directory](https://github.com/the-deep-learners/TensorFlow-LiveLessons/tree/master/installation). 

## Notebooks

All of the code that I cover in the LiveLessons can be found in [this directory](https://github.com/the-deep-learners/TensorFlow-LiveLessons/tree/master/notebooks) as [Jupyter notebooks](http://jupyter.org/). 

Below is the lesson-by-lesson sequence in which I covered them: 

### Lesson One: Introduction to Deep Learning

#### 1.1 Neural Networks and Deep Learning

* via analogy to their biological inspirations, this section introduces Artificial Neural Networks and how they developed to their predominantly *deep* architectures today

#### 1.2 Running the Code in These LiveLessons

* goes over the [installation directory](https://github.com/the-deep-learners/TensorFlow-LiveLessons/tree/master/installation) mentioned above, discussing the options for working through my Jupyter notebooks
* details the [step-by-step installation of TensorFlow on Mac OS X](https://github.com/the-deep-learners/TensorFlow-LiveLessons/blob/master/installation/step_by_step_MacOSX_install.md), a process that may be instructive for users of any Unix-like operating system

#### 1.3 An Introductory Artificial Neural Network

* get your hands dirty with a [simple-as-possible neural network](https://github.com/the-deep-learners/TensorFlow-LiveLessons/blob/master/notebooks/shallow_net_in_keras.ipynb) for classifying handwritten digits
* introduces Jupyter notebooks and their most useful hot keys
* introduces a gentle quantity of deep learning terminology by whiteboarding through:
  * the MNIST digit data set
  * the preprocessing of images for analysis with a neural network
  * a shallow network architecture

### Lesson Two: How Deep Learning Works

#### 2.1 The Families of Deep Neural Nets and their Applications

* talk through the function and popular applications of the predominant modern families of deep neural nets:
  * Dense / Fully-Connected
  * Convolutional Networks (ConvNets)
  * Recurrent Neural Networks (RNNs) / Long Short-Term Memory units (LSTMs)
  * Reinforcement Learning
  * Generative Adversarial Networks

#### 2.2 Essential Theory Iâ€”Neural Units, Cost Functions, Gradient Descent, and Backpropagation

* 
