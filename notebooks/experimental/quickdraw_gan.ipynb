{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Quick, Draw!\" GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* code based directly on [Grant Beyleveld's](https://github.com/grantbey/quickdraw-GAN/blob/master/octopus-v1.0.ipynb), which is derived from [Rowel Atienza's](https://towardsdatascience.com/gan-by-example-using-keras-on-tensorflow-backend-1a6d515a60d0) under [MIT License](https://github.com/roatienza/Deep-Learning-Experiments/blob/master/LICENSE)\n",
    "* data provided by [Google](https://github.com/googlecreativelab/quickdraw-dataset) under [Creative Commons Attribution 4.0 license](https://creativecommons.org/licenses/by/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# JK NOTE: Check that all these dependencies are used\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv2D, AveragePooling2D, Reshape, Dense, BatchNormalization, Dropout, Flatten, UpSampling2D, Conv2DTranspose\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.initializers import TruncatedNormal\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data\n",
    "\n",
    "* NumPy bitmap files [here](https://console.cloud.google.com/storage/browser/quickdraw_dataset/full/numpy_bitmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144722, 28, 28, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('../quickdraw/apple.npy') # PICK YOUR OWN!\n",
    "data = data/255\n",
    "data = np.reshape(data,(data.shape[0],28,28,1))\n",
    "img_w,img_h = data.shape[1:3]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f92b5fc6cf8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIKj/B8WpY6nwmx3pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92b6232438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[42000,:,:,0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_builder(width=64, dropout_prop=0.4):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # convolutional layers\n",
    "    model.add(Conv2D(width, 5, strides=2, padding='same', activation='relu', input_shape=(img_w,img_h,1)))\n",
    "    model.add(Dropout(dropout_prop))\n",
    "    \n",
    "    model.add(Conv2D(width*2, 5, strides=2, padding='same', activation='relu'))\n",
    "    model.add(Dropout(dropout_prop))\n",
    "    \n",
    "    model.add(Conv2D(width*4, 5, strides=2, padding='same', activation='relu'))\n",
    "    model.add(Dropout(dropout_prop))\n",
    "    \n",
    "    model.add(Conv2D(width*8, 5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(Dropout(dropout_prop))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Flatten())    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 4,311,553\n",
      "Trainable params: 4,311,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = discriminator_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminator.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.0002, decay=6e-8), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_builder(z_dim=100, width=64, dropout_prop=0.4):\n",
    "    # has four deconv layers that mirror the discriminator's four conv layers\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # dense layer\n",
    "    square_length = 7\n",
    "    model.add(Dense(square_length*square_length*width, activation='relu', input_shape=(z_dim,)))\n",
    "    model.add(BatchNormalization(axis=-1, momentum=0.9))\n",
    "    model.add(Reshape((square_length,square_length,width)))\n",
    "    model.add(Dropout(dropout_prop))\n",
    "    \n",
    "    # convolutional layers\n",
    "    \n",
    "    model.add(UpSampling2D()) # default is (2,2), mirroring discriminator's stride length of two\n",
    "    model.add(Conv2DTranspose(int(width/2), kernel_size=5, activation='relu')) # a.k.a. \"deconvolution\" layer\n",
    "    model.add(BatchNormalization(axis=-1,momentum=0.9))\n",
    "    \n",
    "    model.add(UpSampling2D()) \n",
    "    model.add(Conv2DTranspose(int(width/4), kernel_size=5, activation='relu')) # a.k.a. \"deconvolution\" layer\n",
    "    model.add(BatchNormalization(axis=-1,momentum=0.9))\n",
    "    \n",
    "#     model.add(UpSampling2D()) # why comment out?\n",
    "    model.add(Conv2DTranspose(int(width/8), kernel_size=5, activation='relu')) # a.k.a. \"deconvolution\" layer\n",
    "    model.add(BatchNormalization(axis=-1,momentum=0.9))\n",
    "    \n",
    "    model.add(Conv2D(1, kernel_size=5, padding='same', activation='sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 18, 18, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 18, 18, 32)        128       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 40, 40, 16)        12816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 40, 40, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 44, 44, 8)         3208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 44, 44, 8)         32        \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 44, 44, 1)         201       \n",
      "=================================================================\n",
      "Total params: 396,961\n",
      "Trainable params: 390,577\n",
      "Non-trainable params: 6,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = generator_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adversarial_builder(z_dim=100):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.0001, decay=3e-8), metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_8 (Sequential)    (None, 44, 44, 1)         396961    \n",
      "_________________________________________________________________\n",
      "sequential_7 (Sequential)    (None, 1)                 4311553   \n",
      "=================================================================\n",
      "Total params: 4,708,514\n",
      "Trainable params: 4,702,130\n",
      "Non-trainable params: 6,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adversarial_model = adversarial_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-daefa00cc187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfake_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0my_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0my_discriminator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "# def train(n_training_steps=2000, batch=128): \n",
    "\n",
    "# for i in range(n_training_steps):\n",
    "batch=128\n",
    "for i in range(1):\n",
    "\n",
    "    real_imgs = np.reshape(data[np.random.choice(data.shape[0],batch,replace=False)], (batch,28,28,1))\n",
    "    fake_imgs = generator.predict(np.random.uniform(-1.0, 1.0, size=[batch, 100]))\n",
    "\n",
    "    x = np.concatenate((real_imgs, fake_imgs))\n",
    "    y_discriminator = np.ones([2*batch,1])\n",
    "    y_discriminator[batch:,:] = 0\n",
    "    d_loss = discriminator.train_on_batch(x,y_discriminator)\n",
    "\n",
    "    noise = np.random.uniform(-1.0, 1.0, size=[batch, 100])\n",
    "    y = np.ones([batch,1])\n",
    "    a_loss = adversarial_model.train_on_batch(noise,y)\n",
    "\n",
    "    log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "    log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "    print(log_mesg)\n",
    "\n",
    "    if (i+1)%1000 == 0:\n",
    "\n",
    "        print('Step #{}'.format(i+1))\n",
    "        log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "        log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "        print(log_mesg)\n",
    "\n",
    "        noise = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        plt.figure(figsize=(5,5))\n",
    "        for k in range(gen_imgs.shape[0]):\n",
    "            plt.subplot(4, 4, k+1)\n",
    "            plt.imshow(gen_imgs[k, :, :, 0], cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig('./gan_images/run1_{}.png'.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a688cd95628d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_training_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-05d58385f60e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_training_steps, batch)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mfake_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0my_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my_discriminator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "train(n_training_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
