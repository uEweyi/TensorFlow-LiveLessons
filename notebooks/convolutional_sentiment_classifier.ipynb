{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Sentiment Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we build a *convolutional* neural net to classify IMDB movie reviews by their sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding\n",
    "from keras.layers import SpatialDropout1D, Conv1D, GlobalMaxPooling1D # new! \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/conv'\n",
    "\n",
    "# training:\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "# vector-space embedding: \n",
    "n_dim = 64\n",
    "n_unique_words = 5000 \n",
    "max_review_length = 400\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2 # new!\n",
    "\n",
    "# convolutional layer architecture:\n",
    "n_conv = 256 # filters, a.k.a. kernels\n",
    "k_conv = 3 # kernel length\n",
    "\n",
    "# dense layer architecture: \n",
    "n_dense = 256\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words) # removed n_words_to_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) \n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "# model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 400, 64)           320000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 400, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 398, 256)          49408     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 435,457\n",
      "Trainable params: 435,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 46s - loss: 0.4798 - acc: 0.7469 - val_loss: 0.2927 - val_acc: 0.8743\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.2514 - acc: 0.8974 - val_loss: 0.2621 - val_acc: 0.8911\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.1748 - acc: 0.9343 - val_loss: 0.2854 - val_acc: 0.8822\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.1182 - acc: 0.9594 - val_loss: 0.3121 - val_acc: 0.8806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f06210868d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 89.1% validation accuracy in epoch 2\n",
    "# ...with second convolutional layer is essentially the same at 89.0%\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.01.hdf5\") # zero-indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24544/25000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0sevRHAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0620ea68d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(roc_auc_score(y_valid, y_hat)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
