{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla LSTM in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use an LSTM to classify IMDB movie reviews by their sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, SpatialDropout1D\n",
    "from keras.layers import SimpleRNN # new! \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/rnn'\n",
    "\n",
    "# training:\n",
    "epochs = 32 # way more!\n",
    "batch_size = 128\n",
    "\n",
    "# vector-space embedding: \n",
    "n_dim = 64 \n",
    "n_unique_words = 10000 \n",
    "max_review_length = 100 # lowered due to vanishing gradient over time\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2 \n",
    "\n",
    "# RNN layer architecture:\n",
    "n_rnn = 256 \n",
    "drop_rnn = 0.2\n",
    "\n",
    "# dense layer architecture: \n",
    "# n_dense = 256\n",
    "# dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words) # removed n_words_to_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) \n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(SimpleRNN(n_rnn, dropout=drop_rnn))\n",
    "# model.add(Dense(n_dense, activation='relu')) # typically don't see top dense layer in NLP like in \n",
    "# model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 64)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 256)               82176     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 722,433\n",
      "Trainable params: 722,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.6847 - acc: 0.5489 - val_loss: 0.6392 - val_acc: 0.6466\n",
      "Epoch 2/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.4599 - acc: 0.7864 - val_loss: 0.4525 - val_acc: 0.8068\n",
      "Epoch 3/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.3182 - acc: 0.8696 - val_loss: 0.3896 - val_acc: 0.8362\n",
      "Epoch 4/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.2732 - acc: 0.8919 - val_loss: 0.3952 - val_acc: 0.8384\n",
      "Epoch 5/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.2215 - acc: 0.9155 - val_loss: 0.4304 - val_acc: 0.8361\n",
      "Epoch 6/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.1768 - acc: 0.9312 - val_loss: 0.4872 - val_acc: 0.8291\n",
      "Epoch 7/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.1450 - acc: 0.9458 - val_loss: 0.5020 - val_acc: 0.7793\n",
      "Epoch 8/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.1081 - acc: 0.9611 - val_loss: 0.5664 - val_acc: 0.8234\n",
      "Epoch 9/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.0865 - acc: 0.9698 - val_loss: 0.6035 - val_acc: 0.8082\n",
      "Epoch 10/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.0817 - acc: 0.9708 - val_loss: 0.6246 - val_acc: 0.8079\n",
      "Epoch 11/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.0695 - acc: 0.9752 - val_loss: 0.7574 - val_acc: 0.8118\n",
      "Epoch 12/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.0655 - acc: 0.9762 - val_loss: 0.7260 - val_acc: 0.8035\n",
      "Epoch 13/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.0518 - acc: 0.9818 - val_loss: 0.7216 - val_acc: 0.8135\n",
      "Epoch 14/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.0570 - acc: 0.9788 - val_loss: 0.8452 - val_acc: 0.8076\n",
      "Epoch 15/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.0360 - acc: 0.9877 - val_loss: 0.9007 - val_acc: 0.8120\n",
      "Epoch 16/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.0319 - acc: 0.9890 - val_loss: 0.7784 - val_acc: 0.7952\n",
      "Epoch 17/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.0491 - acc: 0.9821 - val_loss: 0.8377 - val_acc: 0.7709\n",
      "Epoch 18/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.0795 - acc: 0.9697 - val_loss: 0.8531 - val_acc: 0.8057\n",
      "Epoch 19/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.0355 - acc: 0.9875 - val_loss: 0.9947 - val_acc: 0.8140\n",
      "Epoch 20/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.0348 - acc: 0.9883 - val_loss: 0.9517 - val_acc: 0.7774\n",
      "Epoch 21/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.0357 - acc: 0.9871 - val_loss: 0.9682 - val_acc: 0.7835\n",
      "Epoch 22/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.3811 - acc: 0.7988 - val_loss: 0.6620 - val_acc: 0.5944\n",
      "Epoch 23/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.5950 - acc: 0.6757 - val_loss: 0.6107 - val_acc: 0.6623\n",
      "Epoch 24/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.4172 - acc: 0.8114 - val_loss: 0.4580 - val_acc: 0.8009\n",
      "Epoch 25/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.2657 - acc: 0.8943 - val_loss: 0.4586 - val_acc: 0.8133\n",
      "Epoch 26/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.2357 - acc: 0.9084 - val_loss: 0.5352 - val_acc: 0.8074\n",
      "Epoch 27/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.2130 - acc: 0.9197 - val_loss: 0.4912 - val_acc: 0.8112\n",
      "Epoch 28/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.1825 - acc: 0.9309 - val_loss: 0.5237 - val_acc: 0.8136\n",
      "Epoch 29/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.1611 - acc: 0.9416 - val_loss: 0.5364 - val_acc: 0.8109\n",
      "Epoch 30/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.1468 - acc: 0.9476 - val_loss: 0.5824 - val_acc: 0.8086\n",
      "Epoch 31/32\n",
      "25000/25000 [==============================] - 8s - loss: 0.3088 - acc: 0.8628 - val_loss: 0.5893 - val_acc: 0.7913\n",
      "Epoch 32/32\n",
      "25000/25000 [==============================] - 7s - loss: 0.3136 - acc: 0.8600 - val_loss: 0.6044 - val_acc: 0.7988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc48da5bf98>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 83.8% validation accuracy in epoch 4\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.02.hdf5\") # zero-indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24992/25000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSFKnDABJ6pQBIEmdMgAkqVMGgCR16v8Awlsn3u2lvjkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc48d8b6470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(roc_auc_score(y_valid, y_hat)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
